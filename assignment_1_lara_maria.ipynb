{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGMENT 1\n",
    "\n",
    "## Lara Monteserín Placer\n",
    "\n",
    "## María Ferrero Medina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The aim of this project is to design a machine learning model that is able to predict the energy produced by the Sotavento wind farm. For this purpose, a dataset with 555 features ans 4748 instances is available.\n",
    "\n",
    "The structure of the study will be the following:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Methodology\n",
    "3. KNN model\n",
    "4. Decission tree model\n",
    "5. Ensemble method 1 model\n",
    "6. Ensemble method 2 model\n",
    "7. Selection and performance of the final model\n",
    "\n",
    "For each of the models created, several steps have been followed to optimize each model:\n",
    "\n",
    "a) Hyperparameter tuning\n",
    "b) Imputation techniques\n",
    "c) Feature selection\n",
    "\n",
    "\n",
    "Things to add: - another idea (new library?, new idea...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-hPXBr4r5rS"
   },
   "source": [
    "\n",
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "Before starting to build the model, an EDA is made as a first approach to gain understanding of the dataset. In this Exploratory Data Analysis the data type of the features will be verified, the number of instances and features will be determined. Also, a brief summary of the missing values and columns with constant value will be included. \n",
    "\n",
    "### 1.1. Number of instances and features\n",
    "\n",
    "This dataset has 4748 instances and 555 features.\n",
    "\n",
    "### 1.2. Nature of the variables\n",
    "\n",
    "This dataset contains information about the meteorological conditions in several locations, the time the measures of these conditions were made and the energy produced at each moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy     float64\n",
      "year         int64\n",
      "month        int64\n",
      "day          int64\n",
      "hour         int64\n",
      "            ...   \n",
      "v100.21    float64\n",
      "v100.22    float64\n",
      "v100.23    float64\n",
      "v100.24    float64\n",
      "v100.25    float64\n",
      "Length: 555, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Read the data that is compressed as a gzip\n",
    "wind_ava = pd.read_csv('wind_available.csv.gzip', compression=\"gzip\")\n",
    "\n",
    "# Display the first rows of the dataset just to see it\n",
    "wind_ava.head()\n",
    "\n",
    "# Display the data type of each column\n",
    "column_data_types = wind_ava.dtypes\n",
    "print(column_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked the data types of all the different features, it has been verified that there are:\n",
    "\n",
    "- 551 numerical variables (real numbers). From this 551, one is the energy, that is the output of the problem. And the remaining 550 are relative to the 22 different meteorological conditions measured at the 25 different locations.\n",
    "\n",
    "- 4 numerical variables (integers). These 4 variables are the year, day, month and hour of the day. These variables characterize the moment the measures were taken.\n",
    "\n",
    "### 1.3. Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column  Null Values  NaN Values\n",
      "0     energy            0           0\n",
      "1       year            0           0\n",
      "2      month            0           0\n",
      "3        day            0           0\n",
      "4       hour            0           0\n",
      "..       ...          ...         ...\n",
      "550  v100.21          261         261\n",
      "551  v100.22          387         387\n",
      "552  v100.23          569         569\n",
      "553  v100.24          579         579\n",
      "554  v100.25          436         436\n",
      "\n",
      "[555 rows x 3 columns]\n",
      "Number of columns with Null Values: 550\n",
      "Number of columns with NaN Values: 550\n"
     ]
    }
   ],
   "source": [
    "# Return the number of Null values for each column\n",
    "null_values = wind_ava.isnull().sum()\n",
    "# Return the number of NaN values for each column (just in case they are not the same)\n",
    "nan_values = wind_ava.isna().sum()\n",
    "\n",
    "# Store in missing values the amount of Null and NaN values of each column\n",
    "missing_values = pd.DataFrame({\n",
    "    'Column': null_values.index,\n",
    "    'Null Values': null_values.values,\n",
    "    'NaN Values': nan_values.values\n",
    "})\n",
    "\n",
    "# Print the amount of Null and Nan values\n",
    "print(missing_values)\n",
    "\n",
    "# Identify columns with Null or NaN values\n",
    "columns_with_null = wind_ava.columns[wind_ava.isnull().any()]\n",
    "columns_with_nan = wind_ava.columns[wind_ava.isna().any()]\n",
    "\n",
    "# Display the number of columns which have missing values\n",
    "print(\"Number of columns with Null Values:\", len(columns_with_null))\n",
    "print(\"Number of columns with NaN Values:\", len(columns_with_nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All meteorological variables have missing values in different instances. The 4 categories that characterize the moment the measure was made and the target feature'energy' do not have missing values.\n",
    "\n",
    "\n",
    "### 1.4. Check for constant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for constant values in each column\n",
    "constant_columns = wind_ava.columns[wind_ava.nunique() == 1]\n",
    "\n",
    "# Print columns with constant values\n",
    "print(\"Columns with constant values:\", constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are no constant columns. \n",
    "\n",
    "\n",
    "### 1.5. Type of problem\n",
    "\n",
    "The objective of the model is to estimate the energy, as it is a continuous numerical value, this is a **regression problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology\n",
    "\n",
    "This section will explain the methodology that is going to be followed to evaluate the models. The evaluation tech Which are the outer evaluation and the inner evaluation. And the metrics.\n",
    "\n",
    "- On the one hand, for the **inner evaluation**, crossvalidation will be the method applied. Crossvalidation will be used to determine which is the best combination of hyperparameters. \n",
    "\n",
    "- On the other hand, for the **outer evaluation**, holdout evaluation will be used. Thie method will be used to estimate the future performance of the designed method.\n",
    "\n",
    "Later, to improve the performance of the method, once it is already computed the outer performance, the hyperparameters will be tuned again but this time using the whole dataset.\n",
    "\n",
    "The objective function that is going to be used for the validation of the method is the Mean Squared Error (MSE). This metric is more sensitive to outliers and to distant values as it squares the magnitudes. This is useful to penalize the errors that are larger, and avoid having a model that might have such large errors. \n",
    "\n",
    "**It could be longer this explanation**\n",
    "\n",
    "Note: as the variable that is going to be predicted is the 'energy', only the variables related to the meteorological characteristics will be used. It is considered that the energy produced does not depend on the moment of the day it is being produced.\n",
    "\n",
    "## 3. KNN model\n",
    "\n",
    "First, the simplest model is tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. First approach to the models\n",
    "\n",
    "The idea for this section is to have a first approach for both the KNN and the trees models. This will be done considering all features from the dataset and using the mean as the imputation method. Later on, this two aspects will be changed and it will be checked how that changes affect the model, but first, the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3797294092124536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Split into train and test sets\n",
    "X = wind_ava.drop('energy', axis=1)\n",
    "y = wind_ava['energy']\n",
    "# stratify = y (?)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 100514164)\n",
    "\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "# first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('feature_selection',SelectKBest(f_regression)),('regression',DecisionTreeRegressor())])\n",
    "first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "R_2 = r2_score(y_test,y_predicted)\n",
    "print(R_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17710274456865427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Now we are going to create a basic model but using KNN\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "# first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('feature_selection',SelectKBest(f_regression)),('regression',KNeighborsRegressor(n_neighbors=5))])\n",
    "first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',KNeighborsRegressor(n_neighbors=31))])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "R_2 = r2_score(y_test,y_predicted)\n",
    "print(R_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35045367458558485\n",
      "0.3878773130396762\n",
      "0.38420468177756084\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to perform feature selection by hand\n",
    "\n",
    "# FIRST OPTION - Selecting only the features that correspond to the location 13 (Sotavento)\n",
    "sotavento = wind_ava.filter(regex='\\.13$', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X = sotavento\n",
    "y = wind_ava['energy']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 100514164)\n",
    "\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "# first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('feature_selection',SelectKBest(f_regression)),('regression',DecisionTreeRegressor())])\n",
    "first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "R_2_first = r2_score(y_test,y_predicted)\n",
    "\n",
    "# SECOND OPTION - Selecting the features that correspond to magnitudes related to the wind\n",
    "wind = wind_ava.filter(regex='^(u|v).*$', axis=1)\n",
    "X = sotavento\n",
    "y = wind_ava['energy']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 100514164)\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "second_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "R_2_second = r2_score(y_test,y_predicted)\n",
    "\n",
    "# THIRD OPTION - Selecting the features that correspond to magnitudes related to the wind in Sotavento\n",
    "wind = wind_ava.filter(regex='^(u|v).*\\.13$', axis=1)\n",
    "X = sotavento\n",
    "y = wind_ava['energy']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 100514164)\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "second_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "R_2_third = r2_score(y_test,y_predicted)\n",
    "\n",
    "print(R_2_first)\n",
    "print(R_2_second)\n",
    "print(R_2_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
