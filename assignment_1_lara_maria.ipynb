{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGMENT 1\n",
    "\n",
    "## Lara Monteserín Placer\n",
    "\n",
    "## María Ferrero Medina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The aim of this project is to design a machine learning model that is able to predict the energy produced by the Sotavento wind farm. For this purpose, a dataset with 555 features ans 4748 instances is available.\n",
    "\n",
    "The structure of the study will be the following:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Methodology\n",
    "3. KNN model\n",
    "4. Decission tree model\n",
    "5. Ensemble method 1 model\n",
    "6. Ensemble method 2 model\n",
    "7. Selection and performance of the final model\n",
    "\n",
    "For each of the models created, several steps have been followed to optimize them. First of all, a simple version of each model is created, with hyperparameters that seem reasonable, no feature selection and a basic imputation technique. Then, sequentially, models are improved.\n",
    "\n",
    "1. First model\n",
    "2. Feature selection\n",
    "3. Imputation techniques\n",
    "4. Hyperparameter tuning\n",
    "\n",
    "\n",
    "Things to add: - another idea (new library?, new idea...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-hPXBr4r5rS"
   },
   "source": [
    "\n",
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "Before starting to build the model, an EDA is made as a first approach to gain understanding of the dataset. In this Exploratory Data Analysis the data type of the features will be verified, the number of instances and features will be determined. Also, a brief summary of the missing values and columns with constant value will be included. \n",
    "\n",
    "### 1.1. Number of instances and features\n",
    "\n",
    "This dataset has 4748 instances and 555 features.\n",
    "\n",
    "### 1.2. Nature of the variables\n",
    "\n",
    "This dataset contains information about the meteorological conditions in several locations, the time the measures of these conditions were made and the energy produced at each moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy     float64\n",
      "year         int64\n",
      "month        int64\n",
      "day          int64\n",
      "hour         int64\n",
      "            ...   \n",
      "v100.21    float64\n",
      "v100.22    float64\n",
      "v100.23    float64\n",
      "v100.24    float64\n",
      "v100.25    float64\n",
      "Length: 555, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Read the data that is compressed as a gzip\n",
    "wind_ava = pd.read_csv('wind_available.csv.gzip', compression=\"gzip\")\n",
    "\n",
    "# Display the first rows of the dataset just to see it\n",
    "wind_ava.head()\n",
    "\n",
    "# Display the data type of each column\n",
    "column_data_types = wind_ava.dtypes\n",
    "print(column_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked the data types of all the different features, it has been verified that there are:\n",
    "\n",
    "- 551 numerical variables (real numbers). From this 551, one is the energy, that is the output of the problem. And the remaining 550 are relative to the 22 different meteorological conditions measured at the 25 different locations.\n",
    "\n",
    "- 4 numerical variables (integers). These 4 variables are the year, day, month and hour of the day. These variables characterize the moment the measures were taken.\n",
    "\n",
    "### 1.3. Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column  Null Values  NaN Values\n",
      "0     energy            0           0\n",
      "1       year            0           0\n",
      "2      month            0           0\n",
      "3        day            0           0\n",
      "4       hour            0           0\n",
      "..       ...          ...         ...\n",
      "550  v100.21          261         261\n",
      "551  v100.22          387         387\n",
      "552  v100.23          569         569\n",
      "553  v100.24          579         579\n",
      "554  v100.25          436         436\n",
      "\n",
      "[555 rows x 3 columns]\n",
      "Number of columns with Null Values: 550\n",
      "Number of columns with NaN Values: 550\n"
     ]
    }
   ],
   "source": [
    "# Return the number of Null values for each column\n",
    "null_values = wind_ava.isnull().sum()\n",
    "# Return the number of NaN values for each column (just in case they are not the same)\n",
    "nan_values = wind_ava.isna().sum()\n",
    "\n",
    "# Store in missing values the amount of Null and NaN values of each column\n",
    "missing_values = pd.DataFrame({\n",
    "    'Column': null_values.index,\n",
    "    'Null Values': null_values.values,\n",
    "    'NaN Values': nan_values.values\n",
    "})\n",
    "\n",
    "# Print the amount of Null and Nan values\n",
    "print(missing_values)\n",
    "\n",
    "# Identify columns with Null or NaN values\n",
    "columns_with_null = wind_ava.columns[wind_ava.isnull().any()]\n",
    "columns_with_nan = wind_ava.columns[wind_ava.isna().any()]\n",
    "\n",
    "# Display the number of columns which have missing values\n",
    "print(\"Number of columns with Null Values:\", len(columns_with_null))\n",
    "print(\"Number of columns with NaN Values:\", len(columns_with_nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All meteorological variables have missing values in different instances. The 4 categories that characterize the moment the measure was made and the target feature'energy' do not have missing values.\n",
    "\n",
    "\n",
    "### 1.4. Check for constant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with constant values: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for constant values in each column\n",
    "constant_columns = wind_ava.columns[wind_ava.nunique() == 1]\n",
    "\n",
    "# Print columns with constant values\n",
    "print(\"Columns with constant values:\", constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are no constant columns. \n",
    "\n",
    "\n",
    "### 1.5. Type of problem\n",
    "\n",
    "The objective of the model is to estimate the energy, as it is a continuous numerical value, this is a **regression problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology\n",
    "\n",
    "This section will explain the methodology that is going to be followed to evaluate the models. The evaluation tech Which are the outer evaluation and the inner evaluation. And the metrics.\n",
    "\n",
    "- On the one hand, for the **inner evaluation**, crossvalidation will be the method applied. Crossvalidation will be used to determine which is the best combination of hyperparameters. \n",
    "\n",
    "- On the other hand, for the **outer evaluation**, holdout evaluation will be used. Thie method will be used to estimate the future performance of the designed method.\n",
    "\n",
    "Later, to improve the performance of the method, once it is already computed the outer performance, the hyperparameters will be tuned again but this time using the whole dataset.\n",
    "\n",
    "The objective function that is going to be used for the validation of the method is the Mean Squared Error (MSE). This metric is more sensitive to outliers and to distant values as it squares the magnitudes. This is useful to penalize the errors that are larger, and avoid having a model that might have such large errors. \n",
    "\n",
    "**It could be longer this explanation**\n",
    "\n",
    "Note: as the variable that is going to be predicted is the 'energy', only the variables related to the meteorological characteristics will be used. It is considered that the energy produced does not depend on the moment of the day it is being produced.\n",
    "\n",
    "## 3. KNN Regressor\n",
    "\n",
    "First, the KNN algorithm is used for the predictions.\n",
    "\n",
    "### 3.1. First model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  376408.3075368221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# First, data will be divided into train and test set \n",
    "# Considering it is a time series, it must be split in an appropiate way\n",
    "wind_ava['timestamp'] = pd.to_datetime(wind_ava[['year', 'month', 'day', 'hour']])\n",
    "wind_ava = wind_ava.sort_values(by='timestamp')\n",
    "\n",
    "train_size = 0.8  # Porcentaje de datos para entrenamiento\n",
    "split_index = int(len(wind_ava) * train_size)\n",
    "wind_ava = wind_ava.drop(columns=['timestamp'])\n",
    "\n",
    "# Divide the data into X_train, y_train, X_test, y_test\n",
    "train_data = wind_ava.iloc[:split_index]\n",
    "test_data = wind_ava.iloc[split_index:]\n",
    "\n",
    "X_train = train_data.drop('energy', axis=1)\n",
    "y_train = train_data['energy']\n",
    "X_test = test_data.drop('energy', axis=1)\n",
    "y_test = test_data['energy']\n",
    "\n",
    "# Now the first model will be created\n",
    "first_knn = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',KNeighborsRegressor(n_neighbors=31))])\n",
    "first_knn.fit(X_train,y_train)\n",
    "y_predicted = first_knn.predict(X_test)\n",
    "MSE = mean_squared_error(y_test,y_predicted)\n",
    "\n",
    "print('MSE: ', MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# FIRST OPTION - Univariate technique \n",
    "# Define the first tree as a Pipeline with a preprocessing stage with decision tree\n",
    "first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train,y_train)\n",
    "y_predicted = first_tree.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test,y_predicted)\n",
    "\n",
    "print('MSE: ', MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Feature selection\n",
    "\n",
    "For the feature selection, four different cases have been considered:\n",
    "- Seleting only the features related to the location of the wind farm (Sotavento). This is the features that contain the sufix 13.\n",
    "- Selecting onkly the features related to the wind characteristics. This is the features that start with u or v (the vertical and horizontal components of the wind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  303632.6816254736\n"
     ]
    }
   ],
   "source": [
    "# FIRST OPTION - Selecting only the features that correspond to the location 13 (Sotavento)\n",
    "X_1 = wind_ava.filter(regex='\\.13$', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "y_1 = wind_ava['energy']\n",
    "\n",
    "train_size = 0.8  # Porcentaje de datos para entrenamiento\n",
    "split_index = int(len(X_1) * train_size)\n",
    "\n",
    "# Divide the data into X_train, y_train, X_test, y_test\n",
    "X_train_1 = X_1.iloc[:split_index]\n",
    "X_test_1 = X_1.iloc[split_index:]\n",
    "y_train_1 = y_1.iloc[:split_index]\n",
    "y_test_1 = y_1.iloc[split_index:]\n",
    "\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "# first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('feature_selection',SelectKBest(f_regression)),('regression',DecisionTreeRegressor())])\n",
    "first_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "first_tree.fit(X_train_1,y_train_1)\n",
    "y_predicted_1 = first_tree.predict(X_test_1)\n",
    "MSE_1 = mean_squared_error(y_test_1,y_predicted_1)\n",
    "\n",
    "print('MSE: ', MSE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  279850.94727757893\n"
     ]
    }
   ],
   "source": [
    "# SECOND OPTION - Selecting only the features related to the wind (the ones that start with u or v)\n",
    "X_2 = wind_ava.filter(regex='^(u|v).*$', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "y_2 = wind_ava['energy']\n",
    "\n",
    "train_size = 0.8  # Porcentaje de datos para entrenamiento\n",
    "split_index = int(len(X_2) * train_size)\n",
    "\n",
    "# Divide the data into X_train, y_train, X_test, y_test\n",
    "X_train_2 = X_2.iloc[:split_index]\n",
    "X_test_2 = X_2.iloc[split_index:]\n",
    "y_train_2 = y_2.iloc[:split_index]\n",
    "y_test_2 = y_2.iloc[split_index:]\n",
    "\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "second_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "second_tree.fit(X_train_2,y_train_2)\n",
    "y_predicted_2 = second_tree.predict(X_test_2)\n",
    "MSE_2 = mean_squared_error(y_test_2,y_predicted_2)\n",
    "\n",
    "print('MSE: ', MSE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  302293.82269831584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# THIRD OPTION - Selecting the features that correspond to magnitudes related to the wind in Sotavento\n",
    "X_3 = wind_ava.filter(regex='^(u|v).*\\.13$', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "y_3 = wind_ava['energy']\n",
    "\n",
    "train_size = 0.8  # Porcentaje de datos para entrenamiento\n",
    "split_index = int(len(X_3) * train_size)\n",
    "\n",
    "# Divide the data into X_train, y_train, X_test, y_test\n",
    "X_train_3 = X_3.iloc[:split_index]\n",
    "X_test_3 = X_3.iloc[split_index:]\n",
    "y_train_3 = y_3.iloc[:split_index]\n",
    "y_test_3 = y_3.iloc[split_index:]\n",
    "\n",
    "# Define the first model as a Pipeline with a preprocessing stage with knn\n",
    "third_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "third_tree.fit(X_train_3,y_train_3)\n",
    "y_predicted_3 = third_tree.predict(X_test_3)\n",
    "MSE_3 = mean_squared_error(y_test_3,y_predicted_3)\n",
    "\n",
    "print('MSE: ', MSE_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous results, it is demonstrated that the error from the model improve applying feature selection. The best results are obtained selecting only the features related to the wind. The second best result is obtained selecting only the features from Sotavento and related with the wind.\n",
    "\n",
    "Based on this results, for the KNN model, only the features related to the wind will be selected (second option). So, from now on, it will be used X_2 and y_2.\n",
    "\n",
    "### 4.3. Imputation techniques\n",
    "\n",
    "Once the feature selection has been implemented, it is time to choose the imputation technique that is going to be used. Automtic techniques will be used (instead of manual imputation). Two types of techniques will be considered:\n",
    "- Univariate imputation. That only uses the values from the feature that is going to be imputed. For this it will be used the Simple Imputer, that imputes all the missing values with the mean of the feature. We have chosen the mean instead of the median because there are not many outliers that could affect the distribution of the data. \n",
    "- Multivariate imputation. Which also uses values from other features. Two multivariate imputation techniques are used:\n",
    "- KNN Imputer. Is based on the KNN algorithm.\n",
    "- Iterative Imputer. Is based on iterative models that compute the values for the missing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with :  307378.97239999997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# FIRST: one univariate technique will be used for imputation, this is done with the Simple Imputer, using the mean\n",
    "\n",
    "simple_tree = Pipeline([('imputer',SimpleImputer(strategy = 'mean')),('regression',DecisionTreeRegressor())])\n",
    "\n",
    "simple_tree.fit(X_train_2,y_train_2)\n",
    "y_predicted_2 = simple_tree.predict(X_test_2)\n",
    "MSE_3 = mean_squared_error(y_test_2,y_predicted_2)\n",
    "\n",
    "print('MSE with : ', MSE_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with :  281559.36892273684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# SECOND: KNN\n",
    "\n",
    "knn_tree = Pipeline([('imputer',KNNImputer(n_neighbors=3)),('regression',DecisionTreeRegressor())])\n",
    "\n",
    "knn_tree.fit(X_train_2,y_train_2)\n",
    "y_predicted_2 = knn_tree.predict(X_test_2)\n",
    "MSE_3 = mean_squared_error(y_test_2,y_predicted_2)\n",
    "\n",
    "print('MSE with : ', MSE_3)\n",
    "\n",
    "# 280817.7\n",
    "# 281559.36\n",
    "# Why does MSE change???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with :  265675.5389817895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_tree = Pipeline([('imputer',IterativeImputer(max_iter = 14, random_state = 100515585)),('regression',DecisionTreeRegressor())])\n",
    "\n",
    "iterative_tree.fit(X_train_2,y_train_2)\n",
    "y_predicted_2 = iterative_tree.predict(X_test_2)\n",
    "MSE_3 = mean_squared_error(y_test_2,y_predicted_2)\n",
    "\n",
    "print('MSE with : ', MSE_3)\n",
    "\n",
    "# 258502.783\n",
    "# 281559.36\n",
    "# Why does MSE change???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the version of scikit-learn if it returns an Error with IterativeImputer\n",
    "!pip install --upgrade scikit-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "t_0 = time.time()\n",
    "# Create the ensemble model pipeline\n",
    "random_forest = Pipeline([\n",
    "    ('imputer',KNNImputer(n_neighbors=3)),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42)) \n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bagging Regressor with KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Create the ensemble model pipeline\n",
    "knn_ensemble_pipeline = Pipeline([\n",
    "    ('imputer',KNNImputer(n_neighbors=3)),\n",
    "    ('regressor', BaggingRegressor(base_estimator=KNeighborsRegressor(n_neighbors=5), n_estimators=10, random_state=42))  \n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_ensemble_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = knn_ensemble_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
